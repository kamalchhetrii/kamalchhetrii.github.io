{
  "hash": "ad7e1e3c90a1e34bede5d45c560ecde8",
  "result": {
    "markdown": "---\ntitle: \"Understanding DBSCAN Clustering Analysis in Machine Learning\"\nauthor: \"Kamal Chhetri\"\ndate: \"2023-11-24\"\ncategories:\n  - R\n  - Code\n  - Analysis\n---\n\n\n## Introduction\n\nDensity-Based Spatial Clustering of Applications with Noise (DBSCAN) is a popular clustering algorithm used in machine learning. Unlike other clustering algorithms such as K-means or hierarchical clustering, DBSCAN does not require the user to specify the number of clusters a priori. Instead, it infers the number of clusters based on the data's density.\n\n## How DBSCAN Works\n\nDBSCAN works by defining a cluster as a maximal set of density-connected points. It starts with an arbitrary point in the dataset. If there are at least **`minPts`** within a radius of **`eps`** from that point, a new cluster is created. The algorithm then iteratively adds all directly reachable points to the cluster. Once no more points can be added, the algorithm proceeds to the next unvisited point in the dataset.\n\n## Advantages of DBSCAN\n\nDBSCAN has several advantages over other clustering algorithms:\n\n1.  **No need to specify the number of clusters**: As mentioned earlier, DBSCAN does not require the user to specify the number of clusters a priori. This can be particularly useful when the number of clusters is not known beforehand.\n\n2.  **Ability to find arbitrarily shaped clusters**: Unlike K-means, which tends to find spherical clusters, DBSCAN can find clusters of arbitrary shapes.\n\n3.  **Robustness to noise**: DBSCAN is less sensitive to noise and outliers, as it only adds points that are directly reachable according to the density criteria.\n\n## Disadvantages of DBSCAN\n\nDespite its advantages, DBSCAN also has some limitations:\n\n1.  **Difficulty handling varying densities**: DBSCAN struggles with datasets where clusters have significantly different densities. This is because a single **`eps`** and **`minPts`** value may not be suitable for all clusters.\n\n2.  **Sensitivity to parameter settings**: The results of DBSCAN can be significantly affected by the settings of **`eps`** and **`minPts`**. Choosing appropriate values for these parameters can be challenging.\n\nIn general, density-based clustering algorithms can be quite successful for a wide range of clustering tasks, particularly when the data is shaped and has different densities. When using the algorithm with a specific dataset, it is crucial to pay close attention to the parameters and take the algorithm's constraints into account.\n\nAccording to the research report, the concept of dense regions forms the basis of DBSCAN. It is assumed that points in dense locations make up natural clusters. The term \"dense region\" has to be defined for this. These two parameters are necessary for the DBSCAN algorithm to function.\n\n-   Eps, ε: distance\n\n-   MinPts: The bare minimum of points within a given distance Eps\n\n![In this blog post, we will perform a DBSCAN clustering analysis on an insurance dataset using R.](https://media.geeksforgeeks.org/wp-content/uploads/20190418023034/781ff66c-b380-4a78-af25-80507ed6ff26.jpeg)\n\n## Data:\n\nIn this blog post, we will do the clustering analysis using the DBSCAN clustering method. Regarding the choice of this algorithm is explain above. Please have a look if you want to learn more. Regarding the data, [you can access this data from here](https://www.kaggle.com/code/anujachintyabiswas/mall-customer-hierarchical-kmeans-clustering/input).\n\n#### Load the necessary libraries:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-1_8e00e1bb49f40290ec18e6461234d7cb'}\n\n```{.r .cell-code}\nlibrary(fpc) \nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(dbscan)\n\nknitr::opts_chunk$set(warning = FALSE, message = FALSE)\n```\n:::\n\n\n## Load the data into R:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_dbcb132cfe45343abf22b93692918a3c'}\n\n```{.r .cell-code}\ndata <- read.csv(\"/Users/test/Downloads/Mall_customers.csv\")\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  CustomerID Gender Age Annual_Income Spending_Score\n1          1   Male  19            15             39\n2          2   Male  21            15             81\n3          3 Female  20            16              6\n4          4 Female  23            16             77\n5          5 Female  31            17             40\n6          6 Female  22            17             76\n```\n:::\n\n```{.r .cell-code}\nstr(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t200 obs. of  5 variables:\n $ CustomerID    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ Gender        : chr  \"Male\" \"Male\" \"Female\" \"Female\" ...\n $ Age           : int  19 21 20 23 31 22 35 23 64 30 ...\n $ Annual_Income : int  15 15 16 16 17 17 18 18 19 19 ...\n $ Spending_Score: int  39 81 6 77 40 76 6 94 3 72 ...\n```\n:::\n:::\n\n\n# Preprocessing the data:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_bb539514a0db537c7509dfcfb0ec27f9'}\n\n```{.r .cell-code}\ndata_num <- data[, sapply(data, is.numeric)]\nhead(data_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  CustomerID Age Annual_Income Spending_Score\n1          1  19            15             39\n2          2  21            15             81\n3          3  20            16              6\n4          4  23            16             77\n5          5  31            17             40\n6          6  22            17             76\n```\n:::\n:::\n\n\n## Data Cleaning:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_7438b29aff1216da3ebe9a7e8fb765a2'}\n\n```{.r .cell-code}\n# To see if the given dataset contains any null values or not\nsum(is.na(data_num))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\n#### Explanatory analysis\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_c8d0461f42409f24e2677b0fb6a35f7f'}\n\n```{.r .cell-code}\n# Select the relevant columns\ndata_selected <- data_num[, c('Age', 'Annual_Income', 'Spending_Score')]\n\n# Calculate the correlation matrix\ncorrs <- cor(data_selected)\n\n# Create a heatmap with correlation values\ncorrplot(corrs, method=\"color\", type=\"upper\", order=\"hclust\", \n         addCoef.col = \"black\", # Add correlation coefficients\n         tl.col=\"black\", tl.srt=45) # Text label color and rotation\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nFrom the above correlation table, we can see that either we have negative values which indicated that they are negatively correlated or very low values indicating not a strong correlation between them\n\n#### lets explore the data:\n\n##### Distribution of the variables:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-6_9a0db8fabf7f2bede62edac01acf6393'}\n\n```{.r .cell-code}\n# Create a histogram for 'age'\nggplot(data, aes(x=Age)) +\n  geom_histogram(bins = 30, fill =  \"blue\", color = \"black\") +\n  labs(title=\"Distribution of Age\", x=\"Age\", y=\"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Create a histogram for 'income'\nggplot(data, aes(x=Annual_Income)) +\n  geom_histogram(bins = 30, fill = 'green', color = 'black') +\n  labs(title=\"Distribution of Income\", x=\"Income\", y=\"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#Create a histogram for spending score:\nggplot(data, aes(x=Spending_Score))+\n  geom_histogram(bins = 30, fill='darkgreen', color='black')+\n  labs(title= \"Distribution of Spending Score\", x='spending score', y= 'count')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-3.png){width=672}\n:::\n:::\n\n\nFrom the above distribution, We can see that the age group near 30-40 has the highest density, most customers have income in the range of 50-80k, and most customers have a spending score of 50.\n\n[Lets see the box plot for Gender by Spending Score:]{.underline}\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-7_5565c5859a1aef6bb413c88f88adbdca'}\n\n```{.r .cell-code}\n# Subset the data\nmale_charges <- data[data$Gender == \"Male\", \"Spending_Score\"]\nfemale_charges <- data[data$Gender == \"Female\", \"Spending_Score\"]\n# Create a data frame for plotting\nplot_data <- data.frame(\n  Gender = rep(c(\"Male\", \"Female\"), times = c(length(male_charges), length(female_charges))),\n  Charges = c(male_charges, female_charges)\n)\n# Create the box plot\nggplot(plot_data, aes(x = Gender, y = Charges, fill = Gender)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Box Plot of Charges by Gender\", x = \"Gender\", y = \"Spending Score\", fill = \"Gender\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-8_e15f05f226b794a74ec67c4a1fef7d06'}\n\n```{.r .cell-code}\n#Average Spending score by gender:\n# Calculate the average bmi for each region\navg_bmi_by_region <- data %>%\n  group_by(Gender) %>%\n  summarise(Average_Spending_score = mean(Spending_Score))\n\nprint(avg_bmi_by_region)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  Gender Average_Spending_score\n  <chr>                   <dbl>\n1 Female                   51.5\n2 Male                     48.5\n```\n:::\n:::\n\n\n[Lets see the relationship between Annual income and spending score:]{.underline}\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-9_115278a31e67eeb0c10202c8e9bfa50e'}\n\n```{.r .cell-code}\n# Create a scatter plot with regression line\nggplot(data, aes(x=Annual_Income, y=Spending_Score)) +\n  geom_point() +\n  geom_smooth(method=lm, se=FALSE, color=\"red\") +\n  labs(title=\"Relation between Annual Income and Spending Score\", x=\"Annual Income\", y=\"Spending Score\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nCalculate and print the correlation coefficient:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-10_7542a5eb4e4b518e90245deb788c4d93'}\n\n```{.r .cell-code}\ncorrelation <- cor(data$Annual_Income, data$Spending_Score)\nprint(paste(\"Correlation coefficient: \", correlation))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Correlation coefficient:  0.00990284809403761\"\n```\n:::\n:::\n\n\nFrom this, we can see that there is no correlation between Annual income vs Spending Score.\n\n# Perform DBSCAN Clustering:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-11_c3601f7581fbfef4123bd8d3c24bc81d'}\n\n```{.r .cell-code}\n# Perfom DBSCAN:\n# Select the relevant columns\n# Copy the data\ndf <- data\n\n# Drop the 'CustomerID' column\ndf$CustomerID <- NULL\n\n# Replace 'Gender' values\ndf$Gender <- ifelse(df$Gender == \"Male\", 0, 1)\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-12_e1ee965fcb5b39b9232577e58444a642'}\n\n```{.r .cell-code}\n#Calculate Sihoute score:\n# Load the necessary libraries\nlibrary(dbscan)\nlibrary(cluster)\n\n\n# Define the range of parameter values\neps_values <- seq(11, 16, 1)\nmin_samples_values <- seq(5, 13, 1)\n\n# Initialize vectors to store the results\nclusters <- c()\nsil_score <- c()\n```\n:::\n\n\n## Lets calculate Silhouette Score: \n\nBefore dealing with the calculation of the Silhouette Score, lets get acquainted with what the Silhouette Score is and its importance to us while doing the DBSCAN clustering:\n\nThe Silhouette Score measures how similar an object is to its cluster compared to others. It ranges from -1 to 1, where a high value indicates that the object is well-matched to its cluster and poorly matched to neighboring clusters. The clustering configuration is appropriate if most objects have a high value. If many points have a low or negative value, the clustering configuration may have too many clusters.\n\nThe silhouette score provides a succinct graphical representation of how well each object lies within its cluster. It is a way to track the validity of the clusters formed by the algorithm. It can be particularly useful in the context of DBSCAN, as the algorithm does not explicitly minimize or maximize any particular objective function.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-13_76c5c08d219ea70eb71c31077b66c7d3'}\n\n```{.r .cell-code}\n# Loop over all combinations of parameter values\nfor (eps in eps_values) {\n  for (min_samples in min_samples_values) {\n    # Perform DBSCAN clustering\n    dbscan_result <- dbscan(df, eps = eps, minPts = min_samples)\n    \n    # Append the number of clusters to the 'clusters' vector\n    clusters <- c(clusters, max(dbscan_result$cluster))\n    \n    # Calculate the silhouette score and append it to the 'sil_score' vector\n    sil_score <- c(sil_score, cluster.stats(dist(df), dbscan_result$cluster)$avg.silwidth)\n  }\n}\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n\nWarning in cluster.stats(dist(df), dbscan_result$cluster): clustering\nrenumbered because maximum != number of clusters\n```\n:::\n\n```{.r .cell-code}\n# Create a data frame with the results\ndbscan_df <- expand.grid(Eps = eps_values, Min_Samples = min_samples_values)\ndbscan_df$Number_of_Clusters <- clusters\ndbscan_df$Silhouette_Score <- sil_score\n\n# Print the data frame\nprint(dbscan_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Eps Min_Samples Number_of_Clusters Silhouette_Score\n1   11           5                  5       0.15950489\n2   12           5                  4       0.18222045\n3   13           5                  5       0.04014986\n4   14           5                  4       0.14733884\n5   15           5                  4       0.13127178\n6   16           5                  4       0.09690751\n7   11           6                  3       0.03839425\n8   12           6                  4      -0.04371114\n9   13           6                  4      -0.04716035\n10  14           6                  5       0.17636596\n11  15           6                  3       0.18050065\n12  16           6                  4       0.20657473\n13  11           7                  4       0.20473300\n14  12           7                  4       0.15845864\n15  13           7                  3       0.19532476\n16  14           7                  3       0.19532476\n17  15           7                  3       0.09531062\n18  16           7                  3       0.05953447\n19  11           8                  3       0.19456187\n20  12           8                  4       0.23057899\n21  13           8                  4       0.12729075\n22  14           8                  3       0.19988329\n23  15           8                  4       0.21660975\n24  16           8                  4       0.18699359\n25  11           9                  3       0.24719452\n26  12           9                  3       0.21578135\n27  13           9                  4       0.19421971\n28  14           9                  2       0.26949650\n29  15           9                  4       0.27034017\n30  16           9                  4       0.24966531\n31  11          10                  3       0.25886559\n32  12          10                  3       0.21178070\n33  13          10                  3       0.19155599\n34  14          10                  4       0.22168976\n35  15          10                  3       0.25894850\n36  16          10                  3       0.23688910\n37  11          11                  2       0.27196809\n38  12          11                  2       0.27248722\n39  13          11                  4       0.28921007\n40  14          11                  3       0.26889522\n41  15          11                  4       0.15181851\n42  16          11                  3       0.21849659\n43  11          12                  4       0.24945312\n44  12          12                  4       0.21884485\n45  13          12                  3       0.26591736\n46  14          12                  1       0.32699544\n47  15          12                  1       0.33022559\n48  16          12                  2       0.27662364\n49  11          13                  2       0.25255951\n50  12          13                  3       0.22481604\n51  13          13                  2       0.26248415\n52  14          13                  2       0.22931199\n53  15          13                  2       0.21113928\n54  16          13                  3       0.20679545\n```\n:::\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-14_abd6bed4d953d1b55bc99686123aa824'}\n\n```{.r .cell-code}\n# Convert 'Silhouette_Score' to numeric\ndbscan_df$Silhouette_Score <- as.numeric(as.character(dbscan_df$Silhouette_Score))\n\n# Find the maximum silhouette score\nmax_sil_score <- max(dbscan_df$Silhouette_Score)\n\n# Filter the data frame for the maximum silhouette score\ndbscan_df[dbscan_df$Silhouette_Score == max_sil_score, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Eps Min_Samples Number_of_Clusters Silhouette_Score\n47  15          12                  1        0.3302256\n```\n:::\n:::\n\n\nThe stronger the clustering, the closer the result is near 1. We have reached a maximum Silhouette Score of 0.3302256 with Eps = 15 and Min Samples = 12. To get the best clustering, we will fit these values into the DBSCAN algorithm.\n\n[Perform DBSCAN clustering:]{.underline}\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-15_90f30a55ac0773db4f04140299706ccd'}\n\n```{.r .cell-code}\ndbscan_result <- dbscan(df, eps = 15, minPts = 12)\n\n# Add the cluster assignments to the data frame\ndf$DBSCAN_Clusters <- dbscan_result$cluster\n\n# Sort the data frame by the 'DBSCAN_Clusters' column\ndf <- df[order(df$DBSCAN_Clusters), ]\n\n# Print the data frame\nprint(head(df))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Gender Age Annual_Income Spending_Score DBSCAN_Clusters\n1      0  19            15             39               0\n3      1  20            16              6               0\n5      1  31            17             40               0\n7      1  35            18              6               0\n8      1  23            18             94               0\n9      0  64            19              3               0\n```\n:::\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-16_bdabc7c6384b7e8e69e3bdada30fc0d8'}\n\n```{.r .cell-code}\n# Convert 'DBSCAN_Clusters' to character\ndf$DBSCAN_Clusters <- as.character(df$DBSCAN_Clusters)\n\n# Replace '-1' with 'Outliers'\ndf$DBSCAN_Clusters[df$DBSCAN_Clusters == \"-1\"] <- \"Outliers\"\n\n\n# Create the scatter plot\np <- ggplot(df, aes(x = Annual_Income, y = Spending_Score, color = DBSCAN_Clusters)) +\n  geom_point(size = 4, alpha = 0.8) +\n  scale_color_manual(values = c(\"black\", \"darkred\", \"#0091F7\", \"darkgreen\", \"#F7F700\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20),\n    legend.title = element_text(size = 12),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12)\n  ) +\n  labs(\n    title = \"DBSCAN Clusters\",\n    x = \"Annual Income\",\n    y = \"Sum of Spending Scores\",\n    color = \"Clusters\"\n  )\n\n# Print the plot\nprint(p)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n### Conclusion:\n\nAs we can see, the lack of substantial density in our data causes DBSCAN to perform poorly. The black label indicates outliers, so it will mostly appear as such. Having a more dense data structure means we can get better performance from DBSCAN clustering.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}