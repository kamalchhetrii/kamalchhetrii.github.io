{
  "hash": "72b9587a006a496f617901d6f22c4b5a",
  "result": {
    "markdown": "---\ntitle: \"Anomaly Detection in Machine Learning\"\nauthor: \"Kamal Chhetri\"\ndate: \"2023-10-18\"\ncategories:\n  - R\n  - Code\n  - Analysis\n---\n\n\n### Introduction\n\n## Introduction\n\nAnomaly detection, also known as outlier detection, is a fascinating aspect of machine learning. It involves identifying data points, events, or observations that deviate significantly from the norm. These anomalies can often provide critical and actionable insights in various domains, such as fraud detection in banking, intrusion detection in network security, and fault detection in critical systems.\n\n## What is Anomaly Detection?\n\nAnomaly detection is the process of identifying unexpected items or events in datasets, which differ from the norm. In other words, it's about finding the 'outliers' in your data. For example, in a manufacturing context, an anomalous event could be a sudden increase in defective products.\n\n## Types of Anomalies\n\nThere are three main types of anomalies:\n\n1.  **Point Anomalies**: A single instance of data is anomalous if it's too far off from the rest. For example, spending \\$100 on food every day during the holiday season is normal, but may be odd otherwise.\n\n2.  **Contextual Anomalies**: The abnormality is context-specific. This type of anomaly is common in time-series data. For example, spending \\$100 on food during the holiday season is normal, but may be odd otherwise.\n\n3.  **Collective Anomalies**: A set of data instances collectively helps in detecting anomalies. For example, someone is trying to copy data form a remote machine to a local host unexpectedly, an anomaly that would be flagged as a potential cyber attack.\n\n## Anomaly Detection Techniques\n\nThere are several techniques used for anomaly detection, each with its strengths and weaknesses. Some of the most popular methods include:\n\n1.  **Statistical Methods**: These methods model the normal data behavior using statistical parameters like mean, median, mode, variance, etc. Any data instance that doesn't fit this model is considered an anomaly.\n\n2.  **Machine Learning-Based Methods**: These include techniques like clustering, classification, and nearest neighbors. These methods can either be supervised (labels are available) or unsupervised (no labels).\n\n3.  **Time Series Analysis**: This is particularly useful for sequential data, where some pattern or trend is expected. Techniques used here include state space models, decomposition methods, etc.\n\n![](https://media.geeksforgeeks.org/wp-content/uploads/20190418023034/781ff66c-b380-4a78-af25-80507ed6ff26.jpeg){alt=\"In this blog post, we will perform a DBSCAN clustering analysis on an insurance dataset using R.\"}\n\nLet's get familiar with the fundamental idea underlying the hyperparameters before working with the data. We must examine a few of the hyperparameters that characterize the DBScan job in order to comprehend the idea of the core points. min_samples is the first hyperparameter (HP). This is the bare minimum of core points required for cluster formation. The second crucial HP is 'eps'. \"eps\" is the greatest separation that two samples must have in order to be grouped together. Although border points are somewhat farther from the cluster center, they are nonetheless part of the same cluster as core points. All other data points are referred to as \"Noise Points\" because they are unrelated to any cluster. They require more research because they may be unusual or not.\n\n## About the data:\n\nThere are seven columns and 1338 rows in the data, which indicates that there are seven separate variables. The remaining seven variables---age, sex, bmi, children, smoker, region, and charges. You can access the [data from here](https://github.com/kamalchhetrii/kamalchhetrii.github.io/blob/main/insurance.csv):\n\n## Import necessary libraries:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-1_481b81cf39c9d4fd2c933824afe99d12'}\n\n```{.r .cell-code}\nlibrary(fpc)\nlibrary(ggplot2)\nlibrary(dbscan)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dbscan'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:fpc':\n\n    dbscan\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    as.dendrogram\n```\n:::\n\n```{.r .cell-code}\nlibrary(cluster)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'cluster' was built under R version 4.3.3\n```\n:::\n\n```{.r .cell-code}\nlibrary(FNN)\nlibrary(corrplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ncorrplot 0.92 loaded\n```\n:::\n:::\n\n\n## Import the data set and visualize the data:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_29dca4d6d0659326756b4621f56fbf3e'}\n\n```{.r .cell-code}\ndata <- read.csv(\"/Users/test/Desktop/Kamal/Virginia_Tech_PhD/First semester/Machine_learning/mlblog/kamalchhetrii.github.io/insurance.csv\")\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_1bfa1819854e3a0767379dcddce4ca5c'}\n\n```{.r .cell-code}\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  age    sex    bmi children smoker    region   charges\n1  19 female 27.900        0    yes southwest 16884.924\n2  18   male 33.770        1     no southeast  1725.552\n3  28   male 33.000        3     no southeast  4449.462\n4  33   male 22.705        0     no northwest 21984.471\n5  32   male 28.880        0     no northwest  3866.855\n6  31 female 25.740        0     no southeast  3756.622\n```\n:::\n:::\n\n\n### Lets see if the data contains any null values:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_2769756b96e2cfab61e031d09faa213c'}\n\n```{.r .cell-code}\nsum(is.na(data))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\nThis data set does not contain null values. Thus, we don't have to deal with it further.\n\n### \n\n## Explanatory analysis:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_630c36c7b4164cc50dbb4745b69da9ad'}\n\n```{.r .cell-code}\n# Select the relevant columns\ndata_selected <- data[, c('age', 'bmi', 'charges', 'children')]\n\n# Calculate the correlation matrix\ncorrs <- cor(data_selected)\n\n# Create a heatmap with correlation values\ncorrplot(corrs, method=\"color\", type=\"upper\", order=\"hclust\", \n         addCoef.col = \"black\", # Change correlation coefficients color to white\n         tl.col=\"black\", tl.srt=45, # Text label color and rotation\n         col = colorRampPalette(c(\"blue\", \"white\", \"red\"))(200), # Change color scheme\n         title=\"Correlation Heatmap\") # Add title\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nFrom this, we can see there is not much strong correlation between the different variables.\n\n### Lets see the distribution of charges variable:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-6_242261ead3cc6f5e209906609b4f7681'}\n\n```{.r .cell-code}\n# Create a histogram of charges\nggplot(data, aes(x=charges)) +\n  geom_histogram(binwidth=1000, color=\"black\", fill=\"lightblue\") +\n  labs(title=\"Distribution of Charges\", x=\"Charges\", y=\"Count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nFrom this histogram, we can see the distribution of our charges data which is left skewed and there is the possibility that this data set contains the outlier.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-7_b8bae8c5b7858c4d66d32c3ab9803605'}\n\n:::\n\n\nLet's explore the data set for charges for males and female:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-8_35979a46ceb85aed9d97f3d398eac76d'}\n\n```{.r .cell-code}\n# Create a boxplot of charges by sex\nggplot(data, aes(x=sex, y=charges, color=sex)) +\n  geom_boxplot() +  # Include outliers\n  geom_jitter(width=0.2, alpha=0.5) +  # Add jittered points for better visualization\n  labs(title=\"Charges by Sex\", x=\"Sex\", y=\"Charges\") +\n  theme_minimal() +\n  scale_color_manual(values=c(\"blue\", \"darkgreen\"))  # Specify colors for each sex\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nNow, lets see the charges by bmi for further data exploration:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-9_9b13dc6e7cce35300e13ae316e379604'}\n\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-10_036dfc111ad8542a18a8d2711e307a91'}\n\n```{.r .cell-code}\n# Create a scatter plot of BMI vs charges\nggplot(data, aes(x=bmi, y=charges, color=sex)) +\n  geom_point(alpha=0.5) +  # Add points with transparency for better visualization\n  labs(title=\"BMI vs Charges\", x=\"BMI\", y=\"Charges\") +\n  theme_minimal() +\n  scale_color_manual(values=c(\"red\", \"blue\"))  # Specify colors for each sex\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### \n\n## Calculate the epsilon value using K-distance graph:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-11_18dd42abfe3332481be49fcee2f1d9c7'}\n\n```{.r .cell-code}\n# Load necessary libraries\nlibrary(FNN)\n\n# Select the relevant columns\ndata_selected <- data[, c('age', 'bmi')]\n\n# Standardize the data\ndata_std <- scale(data_selected)\n\n# Compute the nearest neighbors\nk <- 2  # 2 because the point itself is included\nknn_dist <- knn.dist(data_std, k=k)\n\n# Sort the distances\nknn_dist <- sort(knn_dist[,k], decreasing=FALSE)  # Exclude the distance to the point itself\n\n# Plot the k-distance graph\nplot(knn_dist, main=\"K-distance Graph\", xlab=\"Data Points sorted by distance\", ylab=\"Epsilon\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nThe optimum value of epsilon is at the point of maximum curvature in the K-Distance Graph, which is 0.6 in this case. Domain knowledge affects minPoints' value. I'm using 10 minPoints at this time around.\n\nBased on the above calculation, we can do the DBSCAN clustering\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-12_cc4a55209439f11fbbe741d6627e89f4'}\n\n```{.r .cell-code}\n# Select the relevant columns\ndata_selected <- data[, c('age', 'bmi')]\n\n# Standardize the data\ndata_std <- scale(data_selected)\n\n# Perform DBSCAN clustering\ndbscan_res <- dbscan(data_std, eps=0.6, minPts=10)  \nprint(dbscan_res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDBSCAN clustering for 1338 objects.\nParameters: eps = 0.6, minPts = 10\nUsing euclidean distances and borderpoints = TRUE\nThe clustering contains 1 cluster(s) and 3 noise points.\n\n   0    1 \n   3 1335 \n\nAvailable fields: cluster, eps, minPts, dist, borderPoints\n```\n:::\n:::\n\n\n## \n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-13_590313ff183950d29d99a7cf9b7ced28'}\n\n:::\n\n\n## Visualization:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-14_d6235113ebeeb35766d7d64225d68ee0'}\n\n```{.r .cell-code}\n# Add the DBSCAN results to our data\ndata$cluster <- as.factor(dbscan_res$cluster)\n\n# Define colors for each cluster\ncolors <- rainbow(length(unique(dbscan_res$cluster)))\nnames(colors) <- levels(data$cluster)\n\n# Create the plot\nggplot(data, aes(x=age, y=bmi, color=cluster)) +\n  geom_point() +\n  scale_color_manual(values = colors) +\n  theme_minimal() +\n  labs(x=\"Age\", y=\"BMI\", color=\"Cluster\") +\n  theme(legend.position=\"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nFrom the above scatterplot, we can see that three data points are the noise and one cluster with no outliers.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-15_ee16da9a2dfba265edf10d315831c397'}\n\n```{.r .cell-code}\n# Create an outliers data frame\noutliers <- data[data$cluster == -1, ]\n\n# Print the outliers\nprint(outliers)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] age      sex      bmi      children smoker   region   charges  cluster \n<0 rows> (or 0-length row.names)\n```\n:::\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-16_6b35cbcb7bae2ecb80199246fe66bada'}\n\n:::\n\n\n## \n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-17_3dd21d3c6f576eea8616603f84f87b6d'}\n\n:::\n\n\n## \n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-18_3851e397bf9f15650348413e8ae5daa7'}\n\n:::\n\n\n## \n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-19_d8dea3a2dce555a7006e41f130b6d2e6'}\n\n:::\n\n\n## \n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-20_a23bc6343199a3d58f2549f6c1f1b526'}\n\n:::\n\n\n## \n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-21_fee8e83b76ac8284cb1d0b9f4ca8eddd'}\n\n:::\n\n\n## \n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-22_4c95bd811f0cdb6e1a62dd7094959367'}\n\n:::\n\n\n## \n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-23_54acc23f654a0d991688f82fe4e20629'}\n\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-24_81866322902f8274e93a71887d1ac57e'}\n\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-25_54f1a4e074be3567e01663bda3e06e25'}\n\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-26_1371873fb22e18428eed1f0d03693388'}\n\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-27_a23caf851fdbf4e299cb66fe1b16db83'}\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}