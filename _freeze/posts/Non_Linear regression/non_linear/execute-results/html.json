{
  "hash": "1969581401a680f40b2c0a1a9274bc36",
  "result": {
    "markdown": "---\ntitle: \"Understanding Non-Linear Regression\"\nauthor: \"Kamal Chhetri\"\ndate: \"2023-10-18\"\ncategories:\n  - R\n  - Code\n  - Analysis\n---\n\n\n# A. Non Linear regression:\n\n# Introduction:\n\nNon-linear regression is a form of polynomial regression that models a non-linear relationship between dependent and independent variables. It\\'s used when data shows a curvy trend, and linear regression wouldn\\'t yield accurate results due to its assumption of linearity.\n\nThis method can accommodate various types of regression, such as quadratic, cubic, and so on, to fit the dataset.\n\nUnlike simple linear regression, which uses a straight line to relate two variables (X and Y), non-linear regression captures more complex, curved relationships between these variables.\n\nThe main goal of non-linear regression is to minimize the sum of squared differences between the observed Y values and the predictions made by the non-linear model. This sum of squares serves as a measure of how well the model fits the data points. It\\'s calculated by finding the differences between the fitted non-linear function and each data point\\'s Y value, squaring these differences, and then summing them up. A smaller sum of squared differences indicates a better fit of the model to the data.\n\nNon-linear regression employs various mathematical functions such as logarithmic, trigonometric, exponential, power functions, Lorenz curves, Gaussian functions, and other fitting techniques to capture the underlying relationships in the data. This makes it a versatile tool for modeling complex relationships in data.\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Michaelis-Menten_saturation_curve_of_an_enzyme_reaction.svg/300px-Michaelis-Menten_saturation_curve_of_an_enzyme_reaction.svg.png)\n\nFigure: Non linear regression (Fig credit: [Wikipedia](https://en.wikipedia.org/wiki/Nonlinear_regression))\n\n## Working mechanism:\n\nNon-linear regression models the relationship between a dependent variable and one or more independent variables using a non-linear function. This function is typically a polynomial, exponential, logarithmic, or other non-linear function.\n\nThe goal of non-linear regression is to find the parameters that minimize the difference between the predicted and actual output values. This is often done using iterative optimization algorithms, such as gradient descent or Newton\\'s method.\n\n## Lets understand it by example from each:\n\n1.  **Polynomial Regression (Quadratic relationship)**\n\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-1_abf7b2625e0fbcf8eeeaa3f4c8155b59'}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n\n# Generate some sample data\nset.seed(123)\nx <- seq(-10, 10, by = 0.1)\ny <- x^2 + rnorm(length(x), sd = 10)\n\n# Fit a non-linear regression model\nmodel <- nls(y ~ a * x^2, start = list(a = 1))\n\n# Print the model summary\nprint(summary(model))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFormula: y ~ a * x^2\n\nParameters:\n  Estimate Std. Error t value Pr(>|t|)    \na  1.00517    0.01489   67.52   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.533 on 200 degrees of freedom\n\nNumber of iterations to convergence: 1 \nAchieved convergence tolerance: 9.898e-10\n```\n:::\n\n```{.r .cell-code}\n# Plot the data and the fitted model\nggplot(data.frame(x = x, y = y), aes(x = x, y = y)) +\n  geom_point() +\n  stat_function(fun = function(x) coef(model) * x^2, color = \"red\") +\n  labs(x = \"Independent Variable\", y = \"Dependent Variable\", title = \"Quadratic Regression\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](non_linear_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n### **Exponential Regression**\n\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-2_5299efb2987f6d9806f5b68c4024a30e'}\n\n```{.r .cell-code}\n# Generate some sample data\nset.seed(123)\nx <- seq(0, 10, by = 0.1)\ny <- exp(x) + rnorm(length(x), sd = 10)\n\n# Fit a non-linear regression model\nmodel <- nls(y ~ a * exp(b * x), start = list(a = 1, b = 1))\n\n# Print the model summary\nprint(summary(model))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFormula: y ~ a * exp(b * x)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \na 1.0042532  0.0033758   297.5   <2e-16 ***\nb 0.9995746  0.0003516  2843.1   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.085 on 99 degrees of freedom\n\nNumber of iterations to convergence: 2 \nAchieved convergence tolerance: 4.948e-08\n```\n:::\n\n```{.r .cell-code}\n# Plot the data and the fitted model\nggplot(data.frame(x = x, y = y), aes(x = x, y = y)) +\n  geom_point() +\n  stat_function(fun = function(x) coef(model)[1] * exp(coef(model)[2] * x), color = \"red\") +\n  labs(x = \"Independent Variable\", y = \"Dependent Variable\", title = \"Exponential Regression\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](non_linear_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n### **Logarithmic Regression**\n\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-3_41edee23087dc984e01f0f528bce476f'}\n\n```{.r .cell-code}\n# Generate some sample data\nset.seed(123)\nx <- seq(1, 10, by = 0.1)\ny <- log(x) + rnorm(length(x), sd = 0.1)\n\n# Fit a non-linear regression model\nmodel <- nls(y ~ a * log(b * x), start = list(a = 1, b = 1))\n\n# Print the model summary\nprint(summary(model))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFormula: y ~ a * log(b * x)\n\nParameters:\n  Estimate Std. Error t value Pr(>|t|)    \na  1.00204    0.01572   63.73   <2e-16 ***\nb  1.00306    0.02625   38.21   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.08978 on 89 degrees of freedom\n\nNumber of iterations to convergence: 2 \nAchieved convergence tolerance: 4.398e-09\n```\n:::\n\n```{.r .cell-code}\n# Plot the data and the fitted model\nggplot(data.frame(x = x, y = y), aes(x = x, y = y)) +\n  geom_point() +\n  stat_function(fun = function(x) coef(model)[1] * log(coef(model)[2] * x), color = \"red\") +\n  labs(x = \"Independent Variable\", y = \"Dependent Variable\", title = \"Logarithmic Regression\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](non_linear_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n# Lets understand Non- linear regression model by using real data:\n\nNon-linear regression is used when the relationship between the independent and dependent variables is not linear, or when the data is not normally distributed, or involves complex relationships. Non-linear regression can capture complex patterns and interactions and provide impressive results in performance, stability, and precision.\n\n### Data:\n\nYou can access the data [from here](https://www.kaggle.com/datasets/iansurii/china-gdp-dataset). This is the data about the china's GDP per year which is growing in an exponential rate.\n\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-4_8e6c165730107b4e48f151df088d5a2f'}\n\n```{.r .cell-code}\n# Load the package\nlibrary(minpack.lm)\n\ndf <- read.csv(\"/Users/test/Desktop/Machine_learning/mlblog/kamalchhetrii.github.io/china_gdp.csv\")\n```\n:::\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-5_21ffbf95e3fff38a1675d80b4f40b760'}\n\n```{.r .cell-code}\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Year       Value\n1 1960 59184116489\n2 1961 49557050183\n3 1962 46685178504\n4 1963 50097303271\n5 1964 59062254890\n6 1965 69709153115\n```\n:::\n:::\n\n\n### Explanatory visualization:\n\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-6_2e051bd1cee3dd48380a79de8aa54c23'}\n\n```{.r .cell-code}\n# Define the data\nx_data <- df[[\"Year\"]]\ny_data <- df[[\"Value\"]]\n\n# Create the plot\nggplot(df, aes(x = x_data, y = y_data)) +\n  geom_point(color = \"darkgreen\") +\n  labs(x = \"Year\", y = \"GDP\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](non_linear_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n### Building the model:\n\nThe logistic function appears to be a reasonable approximation based on the plot's first appearance. This is because the logistic function begins slowly, grows more rapidly in the middle, and then declines once more in the conclusion.\n\n![](https://raw.githubusercontent.com/Codecademy/docs/main/media/sigmoid-function.png){width=\"435\"}\n\nFigure source: [**Sigmoid Activation Function**](https://www.codecademy.com/resources/docs/ai/neural-networks/sigmoid-activation-function)\n\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-7_f8cfc547ff325fcddd99f629fd44009e'}\n\n```{.r .cell-code}\n# Define the sigmoid function\nsigmoid <- function(x, Beta_1, Beta_2) {\n  y <- 1 / (1 + exp(-Beta_1*(x-Beta_2)))\n  return(y)\n}\n\n# Define the parameters\nbeta_1 <- 0.10\nbeta_2 <- 1990.0\n\n# Apply the logistic function\nY_pred <- sigmoid(x_data, beta_1, beta_2)\n\n# Load necessary library\nlibrary(ggplot2)\n\n# Create a dataframe for plotting\ndf <- data.frame(x = x_data, y = Y_pred * 15000000000000., y_actual = y_data)\n\n# Plot the initial prediction against the data points\nggplot(df, aes(x = x)) +\n  geom_line(aes(y = y), color = \"red\") +\n  geom_point(aes(y = y_actual), color = \"darkgreen\") +\n  labs(x = \"Independent Variable\", y = \"Dependent Variable\")\n```\n\n::: {.cell-output-display}\n![](non_linear_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nNow, we can see the sigmoid and the our actual data plotted in here. We have find the best parameter for our data. We can fit our sigmoid function to the data using curve_fit, which applies non-linear least squares. It is necessary to normalize our x and y variable before proceeding to further data analysis.\n\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-8_97fcd8107539822e3b5c1d2f622bdad7'}\n\n```{.r .cell-code}\n# Normalize the data\nxdata <- x_data / max(x_data)\nydata <- y_data / max(y_data)\n```\n:::\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-9_451004a30937c0b9772466fb9926b6f0'}\n\n```{.r .cell-code}\n# Define the sigmoid function\nsigmoid <- function(x, Beta_1, Beta_2) {\n  y <- 1 / (1 + exp(-Beta_1*(x-Beta_2)))\n  return(y)\n}\n\n# Initial parameter values\nstart <- c(Beta_1 = 1, Beta_2 = 1)\n\n# Non-linear least squares fit\nfit <- nlsLM(ydata ~ sigmoid(xdata, Beta_1, Beta_2), start = start)\n\n# Print the final parameters\nprint(coef(fit))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Beta_1      Beta_2 \n690.4517142   0.9972071 \n```\n:::\n:::\n\n\n## Lets visualize the result obtained from model:\n\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-10_215884b447df267a372a95e32f897ac2'}\n\n```{.r .cell-code}\n# Define the x values\nx <- seq(from = 1960, to = 2015, length.out = 55)\nx <- x / max(x)\n\n# Calculate the y values\ny <- sigmoid(x, coef(fit)[1], coef(fit)[2])\n\n# Create a dataframe for plotting\ndf <- data.frame(x = c(xdata, x), y = c(ydata, y), group = rep(c(\"data\", \"fit\"), each = 55))\n\n# Load necessary library\nlibrary(ggplot2)\n\n# Create the plot\nggplot(df, aes(x = x, y = y, color = group)) +\n  geom_point(data = df[df$group == \"data\", ]) +\n  geom_line(data = df[df$group == \"fit\", ], size = 1.5) +\n  scale_color_manual(values = c(\"darkgreen\", \"blue\")) +\n  labs(x = \"Year\", y = \"GDP\", color = \"Legend\") +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](non_linear_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-11_f2462f4e174e00b39b67ad2b6a1739fd'}\n\n```{.r .cell-code}\n# Define the sigmoid function\nsigmoid <- function(x, Beta_1, Beta_2) {\n  y <- 1 / (1 + exp(-Beta_1*(x-Beta_2)))\n  return(y)\n}\n\n# Split data into train/test\nset.seed(0) # for reproducibility\nmsk <- runif(nrow(df)) < 0.8\ntrain_x <- xdata[msk]\ntest_x <- xdata[!msk]\ntrain_y <- ydata[msk]\ntest_y <- ydata[!msk]\n\n# Initial parameter values\nstart <- c(Beta_1 = 1, Beta_2 = 1)\n\n# Build the model using train set\nfit <- nlsLM(train_y ~ sigmoid(train_x, Beta_1, Beta_2), start = start)\n\n# Print the final parameters\nprint(coef(fit))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Beta_1      Beta_2 \n698.7956319   0.9972452 \n```\n:::\n\n```{.r .cell-code}\n# Predict using test set\ny_hat <- predict(fit, list(x = test_x))\n\nprint(y_hat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 7.073461e-08 1.000734e-07 1.415811e-07 2.833863e-07 8.024885e-07\n [6] 1.135339e-06 1.606245e-06 2.272471e-06 3.215028e-06 4.548528e-06\n[11] 6.435122e-06 9.104212e-06 1.288034e-05 1.822266e-05 3.647350e-05\n[16] 5.160093e-05 1.032782e-04 1.461089e-04 2.066984e-04 2.924063e-04\n[21] 4.136383e-04 5.851038e-04 8.275882e-04 1.655114e-03 2.340004e-03\n[26] 3.307365e-03 4.672760e-03 6.598106e-03 1.311995e-02 1.846129e-02\n[31] 2.592005e-02 3.628093e-02 5.056831e-02 9.633731e-02 1.310586e-01\n[36] 1.758585e-01 2.318858e-01 2.992809e-01 3.766586e-01 4.608835e-01\n[41] 5.474029e-01 6.311496e-01 7.076754e-01 8.289294e-01 8.726981e-01\n```\n:::\n:::\n\n\n### Evaluate the model we developed earlier:\n\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-12_1ced47df91484d4fb0e02b5962a714db'}\n\n```{.r .cell-code}\n# Observed values\ny_obs <- ydata\n\n# Fitted/predicted values\ny_pred <- sigmoid(xdata, coef(fit)[1], coef(fit)[2])\n\n# Calculate RMSE\nrmse <- sqrt(mean((y_obs - y_pred)^2))\n\n# R-squared\nSS_res <- sum((y_obs - y_pred)^2) \nSS_tot <- sum((y_obs - mean(y_obs))^2)\nrsq <- 1 - SS_res/SS_tot\n\n# Print metrics\ncat(\"RMSE:\", rmse, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE: 0.03953521 \n```\n:::\n\n```{.r .cell-code}\ncat(\"R-squared:\", rsq)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR-squared: 0.9726905\n```\n:::\n:::\n\n::: {.cell hash='non_linear_cache/html/unnamed-chunk-13_5c15c2bc86cdbf3dcec06a858083bee4'}\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}