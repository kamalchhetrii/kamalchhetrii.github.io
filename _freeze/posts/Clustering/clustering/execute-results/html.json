{
  "hash": "1ccbece5e5880471ffbb49e18dfbe00d",
  "result": {
    "markdown": "---\ntitle: \"DNSCAN Clustering\"\nauthor: \"Kamal Chhetri\"\ndate: \"2023-10-18\"\ncategories:\n  - R\n  - Code\n  - Analysis\n---\n\n\n# Understanding DBSCAN Clustering Analysis in Machine Learning\n\n## Introduction\n\nDensity-Based Spatial Clustering of Applications with Noise (DBSCAN) is a popular clustering algorithm used in machine learning. Unlike other clustering algorithms such as K-means or hierarchical clustering, DBSCAN does not require the user to specify the number of clusters a priori. Instead, it infers the number of clusters based on the data's density.\n\n## How DBSCAN Works\n\nDBSCAN works by defining a cluster as a maximal set of density-connected points. It starts with an arbitrary point in the dataset. If there are at least **`minPts`** within a radius of **`eps`** from that point, a new cluster is created. The algorithm then iteratively adds all directly reachable points to the cluster. Once no more points can be added, the algorithm proceeds to the next unvisited point in the dataset.\n\n## Advantages of DBSCAN\n\nDBSCAN has several advantages over other clustering algorithms:\n\n1.  **No need to specify the number of clusters**: As mentioned earlier, DBSCAN does not require the user to specify the number of clusters a priori. This can be particularly useful when the number of clusters is not known beforehand.\n\n2.  **Ability to find arbitrarily shaped clusters**: Unlike K-means, which tends to find spherical clusters, DBSCAN can find clusters of arbitrary shapes.\n\n3.  **Robustness to noise**: DBSCAN is less sensitive to noise and outliers, as it only adds points that are directly reachable according to the density criteria.\n\n## Disadvantages of DBSCAN\n\nDespite its advantages, DBSCAN also has some limitations:\n\n1.  **Difficulty handling varying densities**: DBSCAN struggles with datasets where clusters have significantly different densities. This is because a single **`eps`** and **`minPts`** value may not be suitable for all clusters.\n\n2.  **Sensitivity to parameter settings**: The results of DBSCAN can be significantly affected by the settings of **`eps`** and **`minPts`**. Choosing appropriate values for these parameters can be challenging.\n\nIn general, density-based clustering algorithms can be quite successful for a wide range of clustering tasks, particularly when the data is shaped and has different densities. When using the algorithm with a specific dataset, it is crucial to pay close attention to the parameters and take the algorithm's constraints into account.\n\nAccording to the research report, the concept of dense regions forms the basis of DBSCAN. It is assumed that points in dense locations make up natural clusters. The term \"dense region\" has to be defined for this. These two parameters are necessary for the DBSCAN algorithm to function.\n\n-   Eps, ε: distance\n\n-   MinPts: The bare minimum of points within a given distance Eps\n\n![](https://media.geeksforgeeks.org/wp-content/uploads/20190418023034/781ff66c-b380-4a78-af25-80507ed6ff26.jpeg)\n\nIn this blog post, we will perform a DBSCAN clustering analysis on an insurance dataset using R.\n\n## Data: \n\nIn this blog post, we will do the clustering analysis using the DBSCAN clustering method. Regarding the choice of this algorithm is explain above. Please have a look if you want to learn more. Regarding the data, [you can access this data from here](https://github.com/kamalchhetrii/kamalchhetrii.github.io/blob/main/insurance.csv).\n\nLoad necessary libraries\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-1_cf3a542b9fa0901e55058f69f66b5fcd'}\n\n```{.r .cell-code}\nlibrary(fpc) \nlibrary(ggplot2)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n:::\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-2_829e91ce99c3720a340d46093762ab9a'}\n\n```{.r .cell-code}\n# Load the data into R\ndata <- read.csv('/Users/test/Desktop/Machine_learning/mlblog/kchhetrii.github.io/insurance.csv')\n\n# Lets see the couple of rows of this data\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  age    sex    bmi children smoker    region   charges\n1  19 female 27.900        0    yes southwest 16884.924\n2  18   male 33.770        1     no southeast  1725.552\n3  28   male 33.000        3     no southeast  4449.462\n4  33   male 22.705        0     no northwest 21984.471\n5  32   male 28.880        0     no northwest  3866.855\n6  31 female 25.740        0     no southeast  3756.622\n```\n:::\n:::\n\n\nThe dataset contains information about individuals such as their age, sex, BMI, number of children, smoking status, region, and charges.\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-3_7733ffc9a1779fdd49f57336888b5d77'}\n\n```{.r .cell-code}\nstr(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t1338 obs. of  7 variables:\n $ age     : int  19 18 28 33 32 31 46 37 37 60 ...\n $ sex     : chr  \"female\" \"male\" \"male\" \"male\" ...\n $ bmi     : num  27.9 33.8 33 22.7 28.9 ...\n $ children: int  0 1 3 0 0 0 1 3 2 0 ...\n $ smoker  : chr  \"yes\" \"no\" \"no\" \"no\" ...\n $ region  : chr  \"southwest\" \"southeast\" \"southeast\" \"northwest\" ...\n $ charges : num  16885 1726 4449 21984 3867 ...\n```\n:::\n:::\n\n\n# Preprocessing the Data\n\nBefore we can perform DBSCAN clustering, we need to preprocess the data. This typically involves normalizing the data and converting categorical variables into numerical variables. However, for simplicity, let's just use the numerical columns in our dataset:\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-4_d4e8338cdb54d2e667f9e98a5c9b51bc'}\n\n```{.r .cell-code}\ndata_num <- data[, sapply(data, is.numeric)]\nhead(data_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  age    bmi children   charges\n1  19 27.900        0 16884.924\n2  18 33.770        1  1725.552\n3  28 33.000        3  4449.462\n4  33 22.705        0 21984.471\n5  32 28.880        0  3866.855\n6  31 25.740        0  3756.622\n```\n:::\n:::\n\n\n## Data cleaning: \n\nIt is important to see if the data contains any null values. If it has any, please consider removing it.\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-5_654b202b4654582fb09fae1e2a7f0373'}\n\n```{.r .cell-code}\nsum(is.na(data_num))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\nFrom the above code, we can conlcude that this data file doesnot contain any na values. If you choose another data set that contains null value, you can remove them by using the code: data \\<- na.omit(data)\n\n## Explanatory data analysis:\n\nAn overview of a particular database's fundamental statistics is provided in this section. It is an essential step in any analysis since it makes the underlying data easier to comprehend. Distributions and correlations are the two primary sections of this section.\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-6_99567d844e870b08ddfe9b709073eb70'}\n\n```{.r .cell-code}\n# Subset the data\nmale_bmi <- data[data$sex == \"male\", \"bmi\"]\nfemale_bmi <- data[data$sex == \"female\", \"bmi\"]\n\n# Create the histogram for male BMI\nggplot(data.frame(BMI = male_bmi), aes(x = BMI)) +\n  geom_histogram(bins = 30, fill = \"blue\", color= \"black\") +\n  theme_minimal() +\n  labs(title = \"Histogram of Male BMI\", x = \"BMI\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Create the histogram for female BMI\nggplot(data.frame(BMI = female_bmi), aes(x = BMI)) +\n  geom_histogram(bins = 30, fill = \"green\", color=\"black\") +\n  theme_minimal() +\n  labs(title = \"Histogram of Female BMI\", x = \"BMI\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\nThe average bmi rate of Male is higher than female.\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-7_9f2cb055e733de4f5c1d9f8cbe3fcc36'}\n\n```{.r .cell-code}\n# Subset the data\nmale_charges <- data[data$sex == \"male\", \"charges\"]\nfemale_charges <- data[data$sex == \"female\", \"charges\"]\n\n# Create a data frame for plotting\nplot_data <- data.frame(\n  Sex = rep(c(\"Male\", \"Female\"), times = c(length(male_charges), length(female_charges))),\n  Charges = c(male_charges, female_charges)\n)\n\n# Create the box plot\nggplot(plot_data, aes(x = Sex, y = Charges, fill = Sex)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Box Plot of Charges by Sex\", x = \"Sex\", y = \"Charges\", fill = \"Sex\")\n```\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-8_cbb39c5ef6c9bffe94eb642291ce79ec'}\n\n```{.r .cell-code}\n# Calculate the mean separation score and standard deviation for each group\ngrouped_data <- plot_data %>%\n  group_by(Sex) %>%\n  summarise(\n    Mean_Separation_Score = mean(Charges),\n    SD = sd(Charges)\n  )\n\nprint(grouped_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  Sex    Mean_Separation_Score     SD\n  <chr>                  <dbl>  <dbl>\n1 Female                12570. 11129.\n2 Male                  13957. 12971.\n```\n:::\n:::\n\n\nFrom the above data, we can see that the mean separation score for male is higher than female.\n\n## lets see the correlation between different variable to understand the relation:\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-9_9212e35fdf513eec0025104d09b0dd4f'}\n\n```{.r .cell-code}\n# Calculate the average bmi for each region\navg_bmi_by_region <- data %>%\n  group_by(region) %>%\n  summarise(Average_BMI = mean(bmi))\n\nprint(avg_bmi_by_region)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 2\n  region    Average_BMI\n  <chr>           <dbl>\n1 northeast        29.2\n2 northwest        29.2\n3 southeast        33.4\n4 southwest        30.6\n```\n:::\n:::\n\n\nFrom the above graph, we can see that the average bmi of southeast is the highest among all.\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-10_105f06696618d6dc52ae9369102961db'}\n\n```{.r .cell-code}\n# Create the bar plot\nggplot(avg_bmi_by_region, aes(x = region, y = Average_BMI, fill = region)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Average BMI by Region\", x = \"Region\", y = \"Average BMI\", fill = \"Region\")\n```\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n# Perform DBSCAN on the loaded dataset:\n\n## Remove label form dataset\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-11_a470fb27f6964764d7eb9a263311e205'}\n\n```{.r .cell-code}\nmed <- data_num[-4] \n```\n:::\n\n\nFitting DBSCAN clustering model:\n\nDetermining the ideal values is a challenging task that cannot be done at random. As a result, I will start by making a matrix of the options I've looked into.\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-12_9f68a0cc14d194af2393fbd34ae2d1dd'}\n\n:::\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-13_504f9a11401ca28c79d8cd5573dfe17b'}\n\n```{.r .cell-code}\nset.seed(0)  # Setting seed \nDbscan_cl <- dbscan(med, eps = 0.45, MinPts = 5) \nDbscan_cl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ndbscan Pts=1338 MinPts=5 eps=0.45\n          0 1 2 3 4 5\nborder 1310 5 2 4 3 4\nseed      0 1 5 1 1 2\ntotal  1310 6 7 5 4 6\n```\n:::\n:::\n\n\nIn this code, eps is the maximum distance between two samples for them to be considered as in the same neighborhood, and MinPts is the number of samples in a neighborhood for a point to be considered as a core point.\n\n# Visualizing the Results\n\nFinally, let's visualize the results. We will create a scatter plot of the data, with each point colored according to its cluster assignment:\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-14_59f6dae631d32b6cf6c3121b56ab8d4f'}\n\n:::\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-15_5548769cfac42ae5312bc1f386c16ff9'}\n\n```{.r .cell-code}\n# Table \ntable(Dbscan_cl$cluster, data_num$age) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n    18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42\n  0 63 46 29 28 28 28 28 28 28 28 28 27 27 27 26 26 26 25 25 25 25 25 27 27 27\n  1  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  2  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  3  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  4  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  5  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n   \n    43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64\n  0 27 27 29 29 29 29 28 29 29 29 28 28 26 26 26 25 25 23 23 23 23 22\n  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n```\n:::\n:::\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-16_0c5946145c17132882fc228ede7e551c'}\n\n```{.r .cell-code}\n# Plotting Cluster \nplot(Dbscan_cl, med, main = \"DBScan\") \n```\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nIn this plot, points that belong to the same cluster have the same color.\n\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-17_23eece454bb343a40c25e29e19fc700c'}\n\n:::\n\n::: {.cell hash='clustering_cache/html/unnamed-chunk-18_672ef7aea84a07daedad3a5f0c8845b3'}\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}